{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8871cbe5",
   "metadata": {},
   "source": [
    "# Group One\n",
    "## CSC 7333 - Machine Learning project\n",
    "### Comparative Study of Machine Learning Models for Fake News Detection\n",
    "### Andrew Okafor, Dillon Jones, Lin Zeng, Miriam Nnadili, Shaojing Tian, Zack Loken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66d7982",
   "metadata": {},
   "source": [
    "#### Due to the increasing amount of disinformation spreading across the internet, fake news detection using machine learning methods for natural language processing has recently gained much attention. The objective of this project is to compare various machine learning models’ performance in detecting fake news via text classification to see which models perform best. This study used annotated text from various news articles to train and evaluate different classifiers, including logistic regression, naïve Bayes (Gaussian and multinomial), support vector machine, random forest and recurrent neural network hybridize model. The performance on the prediction of accuracy and computational cost for all five classifiers was also compared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce285058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mnnadi1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Original data can be found here: https://www.uvic.ca/ecs/ece/isot/datasets/fake-news/index.php\n",
    "\n",
    "# Import necessary Python libraries, modules, etc.\n",
    "import time # for generating timestamps \n",
    "import re # for regular expressions\n",
    "import string as st # for removing punctuation\n",
    "import numpy as np # for linear algebra\n",
    "import pandas as pd # for frame processing\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "import nltk # for natural language processing\n",
    "from nltk.corpus import stopwords # for removing english stopwords\n",
    "from nltk.stem import WordNetLemmatizer # for term stemming\n",
    "import sklearn # for predictive data analysis\n",
    "from sklearn import preprocessing # for data preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split # for splitting data into test/train sets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # for text vectorization\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from IPython.core.interactiveshell import InteractiveShell # to modify Jupyter notebook configuration\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "InteractiveShell.ast_node_interactivity = \"all\" # so that all outputs in a cell are returned (instead of last instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6313013",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b77a2b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true    21417\n",
      "Name: label, dtype: int64\n",
      "fake    23481\n",
      "Name: label, dtype: int64\n",
      "true    21417\n",
      "Name: label, dtype: int64\n",
      "fake    21417\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23476</th>\n",
       "      <td>McPain: John McCain Furious That Iran Treated ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE reported earl...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23477</th>\n",
       "      <td>JUSTICE? Yahoo Settles E-mail Privacy Class-ac...</td>\n",
       "      <td>21st Century Wire says It s a familiar theme. ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 16, 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23478</th>\n",
       "      <td>Sunnistan: US and Allied ‘Safe Zone’ Plan to T...</td>\n",
       "      <td>Patrick Henningsen  21st Century WireRemember ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 15, 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23479</th>\n",
       "      <td>How to Blow $700 Million: Al Jazeera America F...</td>\n",
       "      <td>21st Century Wire says Al Jazeera America will...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 14, 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23480</th>\n",
       "      <td>10 U.S. Navy Sailors Held by Iranian Military ...</td>\n",
       "      <td>21st Century Wire says As 21WIRE predicted in ...</td>\n",
       "      <td>Middle-east</td>\n",
       "      <td>January 12, 2016</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42834 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      As U.S. budget fight looms, Republicans flip t...   \n",
       "1      U.S. military to accept transgender recruits o...   \n",
       "2      Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3      FBI Russia probe helped by Australian diplomat...   \n",
       "4      Trump wants Postal Service to charge 'much mor...   \n",
       "...                                                  ...   \n",
       "23476  McPain: John McCain Furious That Iran Treated ...   \n",
       "23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
       "23478  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n",
       "23479  How to Blow $700 Million: Al Jazeera America F...   \n",
       "23480  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
       "\n",
       "                                                    text       subject  \\\n",
       "0      WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1      WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2      WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3      WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4      SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "...                                                  ...           ...   \n",
       "23476  21st Century Wire says As 21WIRE reported earl...   Middle-east   \n",
       "23477  21st Century Wire says It s a familiar theme. ...   Middle-east   \n",
       "23478  Patrick Henningsen  21st Century WireRemember ...   Middle-east   \n",
       "23479  21st Century Wire says Al Jazeera America will...   Middle-east   \n",
       "23480  21st Century Wire says As 21WIRE predicted in ...   Middle-east   \n",
       "\n",
       "                     date label  \n",
       "0      December 31, 2017   true  \n",
       "1      December 29, 2017   true  \n",
       "2      December 31, 2017   true  \n",
       "3      December 30, 2017   true  \n",
       "4      December 29, 2017   true  \n",
       "...                   ...   ...  \n",
       "23476    January 16, 2016  fake  \n",
       "23477    January 16, 2016  fake  \n",
       "23478    January 15, 2016  fake  \n",
       "23479    January 14, 2016  fake  \n",
       "23480    January 12, 2016  fake  \n",
       "\n",
       "[42834 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_news = pd.read_csv('true.csv')\n",
    "fake_news = pd.read_csv('fake.csv')\n",
    "true_news['label'] = 'true'  # add an extra column (named \"label\") to the true_news dataframe and assign true to all row in this column\n",
    "fake_news['label'] = 'fake' # add an extra column (named \"label\") to the fake_news dataframe and assign fake to all row in this column\n",
    "\n",
    "#compare the labels to see if the data is balanced\n",
    "print(true_news['label'].value_counts())\n",
    "print(fake_news['label'].value_counts())\n",
    "\n",
    "#randomly remove (n = 2064) rows from the fake_news data frame to balance the labels\n",
    "np.random.seed(5) #you can also use np.random.seed(1) This displays the same random numbers. \n",
    "fake_news = fake_news.drop(np.random.choice(fake_news.index, 2064, replace=False))\n",
    "\n",
    "#compare the labels to see if the data is balanced\n",
    "print(true_news['label'].value_counts())\n",
    "print(fake_news['label'].value_counts())\n",
    "\n",
    "news_data = pd.concat([true_news,fake_news]) # concatenate the fake_news and true_news dataframe \n",
    "news_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2cb006",
   "metadata": {},
   "source": [
    "### Label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5335439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   title  \\\n",
      "0      As U.S. budget fight looms, Republicans flip t...   \n",
      "1      U.S. military to accept transgender recruits o...   \n",
      "2      Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
      "3      FBI Russia probe helped by Australian diplomat...   \n",
      "4      Trump wants Postal Service to charge 'much mor...   \n",
      "...                                                  ...   \n",
      "23476  McPain: John McCain Furious That Iran Treated ...   \n",
      "23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...   \n",
      "23478  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...   \n",
      "23479  How to Blow $700 Million: Al Jazeera America F...   \n",
      "23480  10 U.S. Navy Sailors Held by Iranian Military ...   \n",
      "\n",
      "                                                    text       subject  \\\n",
      "0      WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
      "1      WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
      "2      WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
      "3      WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
      "4      SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
      "...                                                  ...           ...   \n",
      "23476  21st Century Wire says As 21WIRE reported earl...   Middle-east   \n",
      "23477  21st Century Wire says It s a familiar theme. ...   Middle-east   \n",
      "23478  Patrick Henningsen  21st Century WireRemember ...   Middle-east   \n",
      "23479  21st Century Wire says Al Jazeera America will...   Middle-east   \n",
      "23480  21st Century Wire says As 21WIRE predicted in ...   Middle-east   \n",
      "\n",
      "                     date label  target  \n",
      "0      December 31, 2017   true       1  \n",
      "1      December 29, 2017   true       1  \n",
      "2      December 31, 2017   true       1  \n",
      "3      December 30, 2017   true       1  \n",
      "4      December 29, 2017   true       1  \n",
      "...                   ...   ...     ...  \n",
      "23476    January 16, 2016  fake       0  \n",
      "23477    January 16, 2016  fake       0  \n",
      "23478    January 15, 2016  fake       0  \n",
      "23479    January 14, 2016  fake       0  \n",
      "23480    January 12, 2016  fake       0  \n",
      "\n",
      "[42834 rows x 6 columns]\n",
      "                                                    text  target\n",
      "0      As U.S. budget fight looms, Republicans flip t...       1\n",
      "1      U.S. military to accept transgender recruits o...       1\n",
      "2      Senior U.S. Republican senator: 'Let Mr. Muell...       1\n",
      "3      FBI Russia probe helped by Australian diplomat...       1\n",
      "4      Trump wants Postal Service to charge 'much mor...       1\n",
      "...                                                  ...     ...\n",
      "23476  McPain: John McCain Furious That Iran Treated ...       0\n",
      "23477  JUSTICE? Yahoo Settles E-mail Privacy Class-ac...       0\n",
      "23478  Sunnistan: US and Allied ‘Safe Zone’ Plan to T...       0\n",
      "23479  How to Blow $700 Million: Al Jazeera America F...       0\n",
      "23480  10 U.S. Navy Sailors Held by Iranian Military ...       0\n",
      "\n",
      "[42834 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "news_data['target'] = LabelEncoder().fit_transform(news_data['label'])  # add an extra column (named \"target\") which is a transformation of the \"label\" column from text (true or fake) to numbers (1 or 0) using Labelencoder, fit_transform method\n",
    "print(news_data)\n",
    "\n",
    "news_data['text'] = news_data['title'] + news_data['text'] # merge the \"title\" and \"text\" to replace the \"text\" column\n",
    "news_data = news_data[['text','target']] #isolate the merged \"text\" and the \"target\" column\n",
    "print(news_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5279c0a",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf05dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mnnadi1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mnnadi1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnnadi1\\AppData\\Local\\Temp\\ipykernel_21900\\4084964411.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  news_data['text'] = news_data['text'].apply(lambda x: data_cleaning(x))  # apply this to every row in the text column\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>budget fight loom republican flip fiscal scrip...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>military accept transgender recruit monday pen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>senior republican senator let mueller job wash...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fbi russia probe helped australian diplomat ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trump want postal service charge much amazon s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23476</th>\n",
       "      <td>mcpain john mccain furious iran treated sailor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23477</th>\n",
       "      <td>justice yahoo settle mail privacy class action...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23478</th>\n",
       "      <td>sunnistan allied safe zone plan take territori...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23479</th>\n",
       "      <td>blow million jazeera america finally call quit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23480</th>\n",
       "      <td>navy sailor held iranian military sign neocon ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42834 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0      budget fight loom republican flip fiscal scrip...       1\n",
       "1      military accept transgender recruit monday pen...       1\n",
       "2      senior republican senator let mueller job wash...       1\n",
       "3      fbi russia probe helped australian diplomat ti...       1\n",
       "4      trump want postal service charge much amazon s...       1\n",
       "...                                                  ...     ...\n",
       "23476  mcpain john mccain furious iran treated sailor...       0\n",
       "23477  justice yahoo settle mail privacy class action...       0\n",
       "23478  sunnistan allied safe zone plan take territori...       0\n",
       "23479  blow million jazeera america finally call quit...       0\n",
       "23480  navy sailor held iranian military sign neocon ...       0\n",
       "\n",
       "[42834 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function for cleaning data\n",
    "wnl = WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "#this would act on every text in each row (pre-processing the text)\n",
    "def data_cleaning(text):\n",
    "    text = text.lower() # to convert the text to lowercase\n",
    "    text = re.sub('[^a-zA-Z]', ' ',text) # to remove number and special characters \n",
    "    text = text.split()  #to tokenize the text\n",
    "    text = [wnl.lemmatize(word) for word in text if not word in stop_words] #to lemmatize and remove stopwords\n",
    "    text = [word for word in text if len(word) >=3] #remove 3 or less characters; only keep words of length greater than 3\n",
    "    text = ' '.join(text) #to join all tokenized words\n",
    "    return text\n",
    "    \n",
    "news_data['text'] = news_data['text'].apply(lambda x: data_cleaning(x))  # apply this to every row in the text column\n",
    "news_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f265bb7a",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba59b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = news_data.iloc[:, 0]\n",
    "y = news_data.iloc[:, 1]\n",
    "train_data, test_data, train_target, test_target = train_test_split(X, y, random_state = 5, train_size = 0.80) #here you can set random state to 0,1,5 etc. you will have same result for each run. However, setting this to 'None' would yield different results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32a30c",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a5999fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with max_features=1000 and ngram_range=(1,3) further search for combinations of optimal hyperparameters of 4 classifiers\n",
    "vectorizer = TfidfVectorizer(max_features=1000, lowercase=False, ngram_range=(1,3))\n",
    "vec_train_data = vectorizer.fit_transform(train_data).toarray()\n",
    "vec_test_data = vectorizer.fit_transform(test_data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3274f5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=SVC(gamma='auto'), n_iter=2,\n",
       "                   param_distributions={'C': [1, 10, 20],\n",
       "                                        'kernel': ['rbf', 'linear']})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  param_C param_kernel  mean_test_score\n",
      "0      10       linear         0.992967\n",
      "1      20       linear         0.992558\n",
      "The best score for Suppport Vector Machine is 0.9929670140353313\n",
      "The best set of Support Vector Machine hyperparameters are {'kernel': 'linear', 'C': 10}\n"
     ]
    }
   ],
   "source": [
    "# do randomized search for optimal hyperparameters of Support Vector Machine classifier\n",
    "model_SVC = RandomizedSearchCV(SVC(gamma='auto'), \n",
    "                           {'C':[1, 10, 20], 'kernel':['rbf','linear']},\n",
    "                           cv=5, return_train_score=False, n_iter=2)\n",
    "\n",
    "model_SVC.fit(vec_train_data, train_target)\n",
    "\n",
    "df = pd.DataFrame(model_SVC.cv_results_)\n",
    "print(df[['param_C', 'param_kernel', 'mean_test_score']])\n",
    "print (f'The best score for Suppport Vector Machine is {model_SVC.best_score_}')\n",
    "print (f'The best set of Support Vector Machine hyperparameters are {model_SVC.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dcd5779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=MultinomialNB(class_prior=[0.5, 0.5]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'alpha': [1e-05, 0.0005, 0.0001, 0.005,\n",
       "                                                  0.001, 0.05, 0.01, 0.1, 0.5,\n",
       "                                                  1, 5, 10, 50, 100]},\n",
       "                   scoring='roc_auc')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  param_alpha  mean_test_score\n",
      "0           5         0.981213\n",
      "1         0.1         0.982869\n",
      "2         100         0.979237\n",
      "3       0.005         0.983260\n",
      "4        0.05         0.982992\n",
      "5       0.001         0.983383\n",
      "6     0.00001         0.983628\n",
      "7      0.0005         0.983429\n",
      "8        0.01         0.983194\n",
      "9      0.0001         0.983521\n",
      "The best score for MultinomialNB is 0.9836281805030532\n",
      "The best set of MultinomialNB hyperparameters are {'alpha': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "# do randomized search for optimal hyperparameters of MultinomialNB classifier\n",
    "parameters = {'alpha':[0.00001,0.0005, 0.0001,0.005,0.001,0.05,0.01,0.1,0.5,1,5,10,50,100]}\n",
    "model_MNB = RandomizedSearchCV(MultinomialNB(class_prior=[0.5, 0.5]), parameters,n_jobs = -1, cv= 5, scoring='roc_auc')\n",
    "\n",
    "model_MNB.fit(vec_train_data, train_target)\n",
    "\n",
    "df = pd.DataFrame(model_MNB.cv_results_)\n",
    "print (df[['param_alpha', 'mean_test_score']])\n",
    "print (f'The best score for MultinomialNB is {model_MNB.best_score_}')\n",
    "print (f'The best set of MultinomialNB hyperparameters are {model_MNB.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "873e4279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.96562348 0.98972769 0.99244172        nan 0.94805493 0.98485431\n",
      " 0.8692319  0.99250009 0.96089558 0.97656638 0.99334641 0.9116927\n",
      " 0.99308375 0.95141131        nan 0.96541888 0.94726759 0.99133284\n",
      " 0.98462071 0.9559924 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(), n_iter=20,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [3, None],\n",
       "                                        'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001803397B880>,\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001803397B790>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001807A122280>,\n",
       "                                        'n_estimators': [10, 20, 30, 40, 50, 80,\n",
       "                                                         100, 150, 200]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   param_bootstrap param_criterion param_max_depth param_max_features  \\\n",
      "0             True         entropy               3                  9   \n",
      "1            False         entropy            None                  8   \n",
      "2            False         entropy            None                  7   \n",
      "3            False            gini               3                  2   \n",
      "4             True            gini               3                  4   \n",
      "5             True         entropy            None                  3   \n",
      "6            False            gini               3                 10   \n",
      "7             True            gini            None                 10   \n",
      "8            False            gini               3                  7   \n",
      "9            False            gini            None                  5   \n",
      "10            True         entropy            None                 10   \n",
      "11           False         entropy               3                  4   \n",
      "12           False         entropy            None                 10   \n",
      "13            True            gini               3                  8   \n",
      "14            True            gini            None                  2   \n",
      "15            True         entropy            None                  3   \n",
      "16           False            gini               3                  3   \n",
      "17            True         entropy            None                  6   \n",
      "18           False            gini            None                  3   \n",
      "19           False         entropy               3                  3   \n",
      "\n",
      "   param_min_samples_leaf param_min_samples_split  mean_test_score  \n",
      "0                       2                       5         0.965623  \n",
      "1                       4                       3         0.989728  \n",
      "2                       4                       6         0.992442  \n",
      "3                       1                       1              NaN  \n",
      "4                       8                      10         0.948055  \n",
      "5                       1                       6         0.984854  \n",
      "6                       7                       2         0.869232  \n",
      "7                      10                       2         0.992500  \n",
      "8                       4                       6         0.960896  \n",
      "9                       9                      10         0.976566  \n",
      "10                      4                       3         0.993346  \n",
      "11                      2                       7         0.911693  \n",
      "12                      1                      10         0.993084  \n",
      "13                      4                       6         0.951411  \n",
      "14                      3                       1              NaN  \n",
      "15                      9                       9         0.965419  \n",
      "16                      9                       7         0.947268  \n",
      "17                      2                       8         0.991333  \n",
      "18                      4                       6         0.984621  \n",
      "19                     10                       3         0.955992  \n",
      "The best score for Random Forest Classifier is 0.9933464141783404\n",
      "The best set of Random Forest Classifier hyperparameters are {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 10, 'min_samples_leaf': 4, 'min_samples_split': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# do randomized search for optimal hyperparameters of Random Forest classifier\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"n_estimators\":[10, 20,  30,  40, 50, 80,100,150, 200]}\n",
    "\n",
    "model_RFC = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist,\n",
    "                                   n_iter=20)\n",
    "model_RFC.fit(vec_train_data, train_target)\n",
    "\n",
    "df = pd.DataFrame(model_RFC.cv_results_)\n",
    "print (df[['param_bootstrap','param_criterion','param_max_depth','param_max_features','param_min_samples_leaf','param_min_samples_split','mean_test_score']])\n",
    "print (f'The best score for Random Forest Classifier is {model_RFC.best_score_}')\n",
    "print (f'The best set of Random Forest Classifier hyperparameters are {model_RFC.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbd4a932",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "50 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\mnnadi1\\.conda\\envs\\yanma\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.99031139        nan 0.99060326        nan 0.93956299 0.94452404\n",
      " 0.92123627 0.50173636        nan        nan        nan        nan\n",
      " 0.99031139        nan 0.99229582        nan        nan 0.99060326\n",
      " 0.50232001        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001802145DAC0>,\n",
       "                                        'penalty': ['none', 'l1', 'l2',\n",
       "                                                    'elasticnet'],\n",
       "                                        'solver': ['newton-cg', 'lbfgs',\n",
       "                                                   'liblinear']},\n",
       "                   random_state=1, scoring='accuracy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      param_C param_penalty param_solver  mean_test_score\n",
      "0    0.008301          none    newton-cg         0.990311\n",
      "1     0.00001    elasticnet        lbfgs              NaN\n",
      "2    0.000106          none        lbfgs         0.990603\n",
      "3    0.000201            l1    newton-cg              NaN\n",
      "4    0.005989            l2    newton-cg         0.939563\n",
      "5    0.008597            l2    newton-cg         0.944524\n",
      "6     0.00027            l2    newton-cg         0.921236\n",
      "7    0.000016            l2    newton-cg         0.501736\n",
      "8    0.008339            l1        lbfgs              NaN\n",
      "9    0.000096          none    liblinear              NaN\n",
      "10   4.029136            l1        lbfgs              NaN\n",
      "11   0.701873            l1    newton-cg              NaN\n",
      "12  18.291387          none    newton-cg         0.990311\n",
      "13   0.000019    elasticnet    liblinear              NaN\n",
      "14  14.028057            l2    liblinear         0.992296\n",
      "15  50.725544            l1    newton-cg              NaN\n",
      "16   0.001065    elasticnet    newton-cg              NaN\n",
      "17   3.042295          none        lbfgs         0.990603\n",
      "18   0.000017            l2    newton-cg         0.502320\n",
      "19   1.726472    elasticnet    liblinear              NaN\n",
      "The best score for Random Forest Classifier is 0.992295817741797\n",
      "The best set of Random Forest Classifier hyperparameters are {'C': 14.028057068813272, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# do randomized search for optimal hyperparameters of Logistic Regression classifier\n",
    "from scipy.stats import loguniform\n",
    "space = dict()\n",
    "space['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C'] = loguniform(1e-5, 100)\n",
    "model_LRC = RandomizedSearchCV(LogisticRegression(), space, n_iter=20, scoring='accuracy', n_jobs=-1, cv=5, random_state=1)\n",
    "\n",
    "model_LRC.fit(vec_train_data, train_target)\n",
    "\n",
    "df = pd.DataFrame(model_LRC.cv_results_)\n",
    "print (df[['param_C', 'param_penalty','param_solver','mean_test_score']])\n",
    "print (f'The best score for Random Forest Classifier is {model_LRC.best_score_}')\n",
    "print (f'The best set of Random Forest Classifier hyperparameters are {model_LRC.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046413b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be1460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
